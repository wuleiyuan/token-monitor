#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„æ•°æ®ç”Ÿæˆå™¨æ¨¡å—
ç”¨äºä¼ä¸šç‰ˆTokenç›‘æ§ç³»ç»Ÿ
åŸºäºç®€åŒ–ç‰ˆçš„æ•°æ®ç”Ÿæˆé€»è¾‘è¿›è¡Œä¼˜åŒ–
"""

import datetime
import random
from typing import Dict, Any, List, Optional

class DataGenerator:
    """æ•°æ®ç”Ÿæˆå™¨ç±»"""
    
    def __init__(self, seed: Optional[int] = None, use_config_prices: bool = True):
        """
        åˆå§‹åŒ–æ•°æ®ç”Ÿæˆå™¨
        
        Args:
            seed: éšæœºæ•°ç§å­ï¼Œç”¨äºæµ‹è¯•å¯é‡å¤æ€§ã€‚é»˜è®¤Noneè¡¨ç¤ºéšæœºã€‚
            use_config_prices: æ˜¯å¦ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ä»·æ ¼ã€‚é»˜è®¤Trueã€‚
        """
        self.seed = seed
        if seed is not None:
            random.seed(seed)
        
        # é»˜è®¤ä»·æ ¼
        default_prices = {
            "gemini-2.0-flash": 0.01,
            "gemini-2.5-flash": 0.02, 
            "gemini-2.5-pro": 0.05,
            "gemini-3-pro": 0.1
        }
        
        # å°è¯•ä»é…ç½®è·å–ä»·æ ¼
        if use_config_prices:
            try:
                from config_manager import config
                config_prices = config.get_cost_per_1k()
                # æ˜ å°„é…ç½®ä»·æ ¼åˆ°æ¨¡å‹
                self.cost_per_token = {
                    "gemini-2.0-flash": config_prices.get("gemini-2.0-flash", default_prices["gemini-2.0-flash"]),
                    "gemini-2.5-flash": config_prices.get("gemini-2.5-flash", default_prices["gemini-2.5-flash"]),
                    "gemini-2.5-pro": config_prices.get("gemini-2.5-pro", default_prices["gemini-2.5-pro"]),
                    "gemini-3-pro": config_prices.get("gemini-3-pro", default_prices["gemini-3-pro"])
                }
            except ImportError:
                self.cost_per_token = default_prices
        else:
            self.cost_per_token = default_prices
        
        self.models = [
            {"name": "gemini-2.0-flash", "tokens": 500, "weight": 4, "type": "free"},
            {"name": "gemini-2.5-flash", "tokens": 800, "weight": 3, "type": "free"},
            {"name": "gemini-2.5-pro", "tokens": 1200, "weight": 2, "type": "free"},
            {"name": "gemini-3-pro", "tokens": 2000, "weight": 1, "type": "paid"}
        ]
    
    def generate_historical_data(self, days: int = 30) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå†å²æ•°æ®"""
        print(f"ğŸ“Š ç”Ÿæˆè¿‡å»{days}å¤©çš„å†å²æ•°æ®...")
        data = []
        now = datetime.datetime.now()
        
        for days_ago in range(days, 0, -1):
            current_date = now - datetime.timedelta(days=days_ago)
            
            # åŠ¨æ€ç”Ÿæˆæ¯å¤©è®°å½•æ•°é‡ï¼ˆè¶Šè¿‘çš„æ—¥æœŸè®°å½•è¶Šå¤šï¼‰
            base_records = max(1, min(8, int((days - days_ago) / 3) + 2))
            
            for record_idx in range(base_records):
                # ç”Ÿæˆæ—¶é—´åˆ†å¸ƒï¼ˆå·¥ä½œæ—¶é—´9:00-21:00ï¼‰
                hour = 9 + (record_idx * 4) % 13  # é¿å¼€æ·±å¤œæ—¶é—´
                minute = random.randint(0, 59)
                
                timestamp = current_date.replace(hour=hour, minute=minute).strftime("%Y-%m-%d %H:%M:%S")
                
                # æ™ºèƒ½é€‰æ‹©æ¨¡å‹ï¼ˆæ ¹æ®çœŸå®ä½¿ç”¨æ¨¡å¼ï¼‰
                model = self._smart_select_model(current_date.hour)
                
                # æ·»åŠ éšæœºå˜åŒ–
                token_variation = random.randint(-300, 500)
                tokens = max(50, model["tokens"] + token_variation)
                
                # è®¡ç®—æˆæœ¬
                cost = (tokens / 1000) * self.cost_per_token[model["name"]]
                
                # æ¨¡æ‹Ÿå“åº”æ—¶é—´ï¼ˆä¸æ¨¡å‹å¤æ‚åº¦ç›¸å…³ï¼‰
                base_response_time = {
                    "gemini-2.0-flash": 120,
                    "gemini-2.5-flash": 180,
                    "gemini-2.5-pro": 300,
                    "gemini-3-pro": 450
                }
                
                response_time = base_response_time[model["name"]] + random.randint(-50, 100)
                
                # çŠ¶æ€æ¨¡æ‹Ÿï¼ˆå¤§éƒ¨åˆ†æˆåŠŸï¼‰
                status = random.choices(
                    ["success", "success", "success", "failed"], 
                    weights=[95, 95, 95, 5]  # 95%æˆåŠŸç‡
                )[0]
                
                data.append({
                    "timestamp": timestamp,
                    "model_name": model["name"],
                    "model": model["name"].replace("gemini-", "").replace("-", " ").upper(),
                    "tokens_used": tokens,
                    "tokens": tokens,
                    "cost": round(cost, 4),
                    "provider": "google",
                    "session_id": f"historical_{days_ago}_{record_idx}",
                    "type": model["type"],
                    "responseTime": response_time,
                    "status": status
                })
        
        print(f"âœ… å·²ç”Ÿæˆ {len(data)} æ¡å†å²æ•°æ®")
        return data
    
    def generate_today_data(self, records_count: int = 5) -> List[Dict[str, Any]]:
        """ç”Ÿæˆä»Šæ—¥æ•°æ®"""
        print(f"ğŸ“Š ç”Ÿæˆä»Šæ—¥{records_count}æ¡æ•°æ®...")
        now = datetime.datetime.now()
        data = []
        
        # ä»Šæ—¥æ•°æ®åº”è¯¥æ›´åŠ çœŸå®ï¼Œä½“ç°å®é™…ä½¿ç”¨æ¨¡å¼
        today_scenarios = [
            {
                "hour": 9, "minute": 30, "model": "gemini-2.0-flash", "tokens": 600,
                "scenario": "æ™¨é—´å¿«é€ŸæŸ¥è¯¢"
            },
            {
                "hour": 11, "minute": 45, "model": "gemini-2.5-flash", "tokens": 1200,
                "scenario": "æ—¥å¸¸å·¥ä½œå¤„ç†"
            },
            {
                "hour": 14, "minute": 15, "model": "gemini-2.5-pro", "tokens": 800,
                "scenario": "ä¸‹åˆä»£ç ç”Ÿæˆ"
            },
            {
                "hour": 16, "minute": 45, "model": "gemini-3-pro", "tokens": 1500,
                "scenario": "å¤æ‚ä»»åŠ¡å¤„ç†"
            },
            {
                "hour": 20, "minute": 30, "model": "gemini-2.5-flash", "tokens": 400,
                "scenario": "æ™šé—´å­¦ä¹ "
            }
        ]
        
        for i, scenario in enumerate(today_scenarios[:records_count]):
            timestamp = now.replace(
                hour=scenario["hour"], 
                minute=scenario["minute"]
            ).strftime("%Y-%m-%d %H:%M:%S")
            
            model = next(m for m in self.models if m["name"] == scenario["model"])
            
            # è®¡ç®—æˆæœ¬
            cost = (scenario["tokens"] / 1000) * self.cost_per_token[model["name"]]
            
            # å“åº”æ—¶é—´åŸºäºåœºæ™¯è°ƒæ•´
            base_time = {
                "gemini-2.0-flash": 120, "gemini-2.5-flash": 180,
                "gemini-2.5-pro": 300, "gemini-3-pro": 450
            }
            response_time = base_time[model["name"]] + random.randint(-30, 60)
            
            data.append({
                "timestamp": timestamp,
                "model_name": model["name"],
                "model": model["name"].replace("gemini-", "").replace("-", " ").upper(),
                "tokens_used": scenario["tokens"],
                "tokens": scenario["tokens"],
                "cost": round(cost, 4),
                "provider": "google",
                "session_id": f"today_scenario_{i}",
                "type": model["type"],
                "responseTime": response_time,
                "status": "success",
                "scenario": scenario["scenario"]
            })
        
        print(f"âœ… å·²ç”Ÿæˆä»Šæ—¥{len(data)}æ¡æ•°æ®")
        return data
    
    def _smart_select_model(self, hour: int) -> Dict[str, Any]:
        """æ ¹æ®æ—¶é—´æ™ºèƒ½é€‰æ‹©æ¨¡å‹"""
        # å·¥ä½œæ—¶é—´æ›´å¯èƒ½ä½¿ç”¨å¤æ‚æ¨¡å‹
        if 9 <= hour <= 17:
            # å·¥ä½œæ—¶é—´ï¼šæœ‰æ›´é«˜æ¦‚ç‡ä½¿ç”¨ä»˜è´¹æ¨¡å‹
            weights = [2, 3, 2, 1]  # ä»˜è´¹æ¨¡å‹æƒé‡æ›´é«˜
        else:
            # éå·¥ä½œæ—¶é—´ï¼šæ›´å¤šä½¿ç”¨å…è´¹æ¨¡å‹
            weights = [4, 3, 2, 1]
        
        return random.choices(self.models, weights=weights)[0]
    
    def generate_realistic_data(self, total_records: int = 200) -> List[Dict[str, Any]]:
        """ç”ŸæˆçœŸå®æ„Ÿçš„æ•°æ®ï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆï¼‰"""
        print(f"ğŸ“Š ç”Ÿæˆ{total_records}æ¡çœŸå®æ„Ÿæ•°æ®...")
        now = datetime.datetime.now()
        
        # ä¼˜åŒ–ï¼šåŠ¨æ€è®¡ç®—éœ€è¦çš„å¤©æ•°ï¼Œé¿å…ç”Ÿæˆè¿‡å¤šæ•°æ®
        # å‡è®¾æ¯å¤©æœ€å¤š8æ¡è®°å½•ï¼Œæ ¹æ®total_recordsè®¡ç®—éœ€è¦çš„å¤©æ•°
        max_days_needed = min(90, (total_records // 3) + 10)
        
        data = []
        
        # åªç”Ÿæˆéœ€è¦çš„å¤©æ•°èŒƒå›´
        for days_ago in range(max_days_needed, 0, -1):
            if len(data) >= total_records:
                break
                
            current_date = now - datetime.timedelta(days=days_ago)
            
            # æ¯å¤©éšæœºç”Ÿæˆ0-8æ¡è®°å½•
            daily_records = random.randint(0, 8)
            
            for i in range(daily_records):
                if len(data) >= total_records:
                    break
                    
                # æ™ºèƒ½æ—¶é—´åˆ†å¸ƒ
                if 6 <= i <= 8:
                    hour = 9 + i  # 9:00-17:00
                else:
                    hour = random.choice([19, 20, 21])
                
                timestamp = current_date.replace(hour=hour, minute=random.randint(0, 59))
                
                # å‘¨æœŸæ¨¡å¼
                if current_date.weekday() >= 5:
                    weights = [3, 4, 2, 1]
                else:
                    weights = [4, 3, 2, 1]
                
                model = random.choices(self.models, weights=weights)[0]
                
                # é”™è¯¯é‡è¯•æ¨¡å¼
                if random.random() < 0.1:
                    tokens = random.randint(100, 500)
                    response_time = random.randint(1000, 3000)
                    status = "failed"
                else:
                    token_variation = random.randint(-200, 800)
                    tokens = max(50, model["tokens"] + token_variation)
                    base_time = {
                        "gemini-2.0-flash": 120, "gemini-2.5-flash": 180,
                        "gemini-2.5-pro": 300, "gemini-3-pro": 450
                    }
                    response_time = base_time[model["name"]] + random.randint(-50, 200)
                    status = "success"
                
                cost = (tokens / 1000) * self.cost_per_token[model["name"]]
                
                data.append({
                    "timestamp": timestamp.strftime("%Y-%m-%d %H:%M:%S"),
                    "model_name": model["name"],
                    "model": model["name"].replace("gemini-", "").replace("-", " ").upper(),
                    "tokens_used": tokens,
                    "tokens": tokens,
                    "cost": round(cost, 4),
                    "provider": "google",
                    "session_id": f"realistic_{days_ago}_{i}",
                    "type": model["type"],
                    "responseTime": response_time,
                    "status": status
                })
        
        # æŒ‰æ—¶é—´æ’åº
        data.sort(key=lambda x: x["timestamp"], reverse=False)
        
        print(f"âœ… å·²ç”Ÿæˆ{len(data)}æ¡çœŸå®æ„Ÿæ•°æ®")
        return data[:total_records]
    
    def get_data_summary(self, data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è·å–æ•°æ®æ‘˜è¦"""
        if not data:
            return {"total_records": 0}
        
        total_tokens = sum(item["tokens"] for item in data)
        total_cost = sum(item["cost"] for item in data)
        model_stats = {}
        provider_stats = {}
        
        for item in data:
            model = item["model_name"]
            model_stats[model] = model_stats.get(model, 0) + 1
            
            provider = item["provider"]
            provider_stats[provider] = provider_stats.get(provider, 0) + 1
        
        return {
            "total_records": len(data),
            "total_tokens": total_tokens,
            "total_cost": total_cost,
            "model_stats": model_stats,
            "provider_stats": provider_stats,
            "date_range": f"{data[-1]['timestamp'][:10]} è‡³ {data[0]['timestamp'][:10]}" if data else "N/A"
        }